#  üô§ **PARTIE 2** üôß

# Extraction structur√©e des indices g√©ographiques dans les m√©tadonn√©es des photographies d'[Eug√®ne Atget](https://fr.wikipedia.org/wiki/Eug%C3%A8ne_Atget)


üôë Au-del√† de son volume, l'≈ìuvre d'Eug√®ne Atget frappe par la m√©ticulosit√© de son classement. V√©ritable archiviste de son propre travail, l‚Äôauteur a syst√©matiquement index√© ses clich√©s, les structurant en s√©ries et en albums th√©matiques. Chaque clich√© est dot√© d'un titre d√©crivant son sujet et sa localisation, souvent tr√®s pr√©cis√©ment.

Ces titres, syst√©matiquement relev√©s et transcrits, font parti des m√©tadonn√©es associ√©es √† chaque photographie. Les archivistes ne se sont cependant pas arr√™t√© l√† et ont enrichi la description structur√©e de chaque clich√© avec des th√®mes issus du th√©saurus Rameau.

La richesse g√©ographique de ces m√©tadonn√©es permet aujourd'hui d'envisager une cartographie du fonds dans l‚Äôespace parisien. Cette approche, image par image, offrirait un parcours in√©dit au c≈ìur de la capitale et renouvellerait notre regard sur l‚Äô≈ìuvre du photographe.

üôë **Rappel**. Dans la [partie 1](https://github.com/HueyNemud/tnah-2026-partie1), nous avons explor√© le graphe de connaissances de la biblioth√®que nationale de France, publi√© sur data.bnf.fr, analys√© le sch√©ma de m√©tadonn√©es *WEMI* utilis√© pour structurer les m√©tadonn√©es descriptives des ≈ìuvres, et extrait pour chaque photographie un graphe RDF contenant les m√©tadonn√©es la d√©crivant. Dans le chapitre 4, les graphes individuels des photographies ont √©t√© enregistr√©s au format Turtle sur le disque, dans un dossier nomm√© `photographies/`

**‚ö†Ô∏è Pr√©requis**
- Avoir termin√© la partie 1.
- Le dossier `photographies/` doit exister dans le r√©pertoire de la partie 1 et doit contenir les fichiers `<ark>.ttl` de chaque photographie assign√©e √† votre √©quipe.

<hr/>

##  üô§ Objectifs
Cette seconde partie guide la mise en place d'un processus d'extraction de l'information g√©ographique contenue dans les m√©tadonn√©es des photographies d'Eug√®ne Atget r√©colt√©es dans la premi√®re partie.

 Elle se d√©compose en deux √©tapes :

1. D'abord enrichir les graphes de m√©tadonn√©es des photographies avec les **th√®mes Rameau** qui leurs sont associ√©s, afin d'obtenir le plus possible d'indications g√©ographiques. Cette premi√®re √©tape est l'occasion d'un **exercice de lecture de code** Python.

2. Ensuite, **extraire l'information g√©ographique pertinente** dans le titre et des th√®mes de chaque photographie pour obtenir un ensemble d'indications de localisation qui pourront √™tre utilis√© pour placer la photographie dans Paris et ses alentours. Cette t√¢che de **traitement automatique du langage naturel** sera r√©alis√© avec un **grand mod√®le de langage g√©n√©ratif**.

L√©gende des pictogrammes utilis√©s :

| Picto. | L√©gende                                   |
| ------ | ----------------------------------------- |
| üé¨      | Action √† r√©aliser : √† vous de jouer !     |
| üí°      | Suggestion d'action compl√©mentaire        |
| ‚ö†Ô∏è      | Avertissement                             |
| ‚ÑπÔ∏è      | Information suppl√©mentaire ou astuce      |
| üìö      | Ressources : documentation, article, etc. |
 
<hr/>

##  üô§ Chapitre 2 : extraction structur√©e de l'information g√©ographique contenue dans les m√©tadonn√©es des photographies

### Motivation
Le premier chapitre a permis d'ajouter √† chaque graphe de photographie les informations textuelles des th√®mes Rameau associ√©s.
Par exemple :
```raw
=== PHOTO : Au Soleil d'or : 84 [quatre-vingt-quatre] Rue S.t Sauveur (Modifi√©), [photographie] ===
Lien : http://data.bnf.fr/ark:/12148/cb40268281c#about
Th√®mes assign√©s:
 ‚Ä¢ ¬´ Dans l'art ¬ª - altLabels : ¬´ Repr√©sentation dans l'art ¬ª, ¬´ Dans la sculpture ¬ª, ¬´ Dans la peinture ¬ª, ¬´ Repr√©sentation iconographique ¬ª, ¬´ Dans les arts graphiques ¬ª
 ‚Ä¢ ¬´ Caf√©s ¬ª - altLabels : ¬´ Caf√©s-bars ¬ª, ¬´ D√©bits de boissons ¬ª, ¬´ Estaminets ¬ª, ¬´ Brasseries (caf√©s) ¬ª, ¬´ Zincs (caf√©s) ¬ª, ¬´ Bistrots ¬ª, ¬´ Caf√©s publics ¬ª, ¬´ Caf√©s (√©tablissements) ¬ª, ¬´ Bars ¬ª
 ‚Ä¢ ¬´ Paris (France) ¬ª
 ‚Ä¢ ¬´ Paris (France) -- Rue Saint-Sauveur ¬ª - altLabels : ¬´ Rue Saint-Sauveur (Paris, France) ¬ª, ¬´ Saint-Sauveur, Rue (Paris, France) ¬ª
 ‚Ä¢ ¬´ Enseignes ¬ª - altLabels : ¬´ Signes et indications ¬ª, ¬´ Enseignes commerciales ¬ª
 ‚Ä¢ ¬´ Ferronnerie d'art ¬ª - altLabels : ¬´ Serrurerie d'art ¬ª, ¬´ Fer forg√©, Objets en ¬ª, ¬´ Fer ornemental ¬ª, ¬´ Ferronnerie architecturale ¬ª, ¬´ Ferrures ¬ª, ¬´ Ferronneries ¬ª, ¬´ Ferronnerie d√©corative ¬ª, ¬´ Fer forg√© ¬ª, ¬´ Objets en fer forg√© ¬ª, ¬´ Ferronnerie (architecture) ¬ª
 ‚Ä¢ ¬´ Soleil ¬ª - altLabels : ¬´ Physique solaire ¬ª
```

On rep√®re de nombreuses informations g√©ographiques qui renseignent plus ou moins pr√©cis√©ment sur la localisation de cette photographie:
1. Le **titre** de la photo contient un toponyme, ¬´ Au Soleil d'or ¬ª, ainsi qu'une adresse postal : ¬´ 84 S.t Sauveur ¬ª
2. Les **th√®mes Rameau** donnent une s√©rie d'indices g√©ographiques suppl√©mentaires, ex. ¬´ Paris (France) -- Rue Saint-Sauveur ¬ª

En lisant ces m√©tadonn√©es, un humain peut imm√©diatement identifier une **hi√©rarchie spatiale** : 
```raw
üìç France [pays]
‚îî‚îÄ‚îÄ üèôÔ∏è Paris [ville]
    ‚îî‚îÄ‚îÄ üõ£Ô∏è rue Saint-Sauveur [rue]
        ‚îî‚îÄ‚îÄ üè† n¬∞ 84 rue Saint-Sauveur [adresse]
            ‚îî‚îÄ‚îÄ ‚òÄÔ∏è ¬´ Au Soleil d'or ¬ª [lieu dit / enseigne]
```

Avoir une hi√©rarchie spatiale est extr√™mement pr√©cieux pour le g√©ocodage car on peut alors chercher √† localiser une photo au niveau le plus fin, puis remonter dans la hi√©rarchie si cela n'est pas possible, par exemple parce que le lieu a disparu.
C'est aussi un moyen √©l√©gant de regrouper les photos par niveau de granularit√© spatiale.

Cette op√©ration qui couple lecture, identification de l'information utile et d√©duction d'une hi√©rarchie est intuitive pour un humain, mais est en r√©alit√© assez complexe pour une machine. En effet, elle repose sur une compr√©hension contextuelle des th√®mes et implique une connaissance implicite. 
Pour une machine, "Paris (France)" est juste une cha√Æne de caract√®re.
Comprendre que le texte "84 [quatre-vingt-quatre] Rue S.t Sauveur" correspond √† une adresse et peut √™tre normalis√© en "84 rue Saint-Sauveur" n√©cessite de coder des r√®gles sp√©cifiques, ce qui devient rapidement √† la fois lourd et fragile.
 
Heureusement, les **grands mod√®les de langages (LLMs)** offrent une alternative particuli√®rement adapt√©e √† ce genre de tache qui m√™le compr√©hension, extraction et g√©n√©ration, gr√¢ce √† leurs capacit√©s de raisonnement de haut niveau.

Pour des raisons de simplicit√©, l'exp√©rimentation sera r√©alis√©e avec les mod√®les de **[Mistral](https://mistral.ai/fr)**.

### Un *prompt* na√Øf pour extraire une hi√©rarchie g√©ographique dans les titres et th√®mes d'une photographie.

Un grand mod√®le de langage peut √™tre guid√© par des instructions pour r√©aliser une t√¢che de traitement de donn√©es sans qu'il soit n√©cessaire de l'entra√Æner sp√©cialement sur cette t√¢che.

Ces instructions sont rassembl√©es dans un texte donn√© au mod√®le  nomm√© **prompt**. 
S'il n'existe pas de "bible" de la r√©daction de prompt, il y a quand m√™me des r√®gles g√©n√©rales qui d√©crivent la structure g√©n√©rale d'un prompt basique :

> a. Assigner un r√¥le au mod√®le pour la tache.
> b. D√©crire la t√¢che √† r√©aliser
> c. Si n√©cessaire, donner des r√®gles sp√©cifiques pour g√©rer les cas complexes, ambigus, etc.

Voici un *prompt* simpliste que l'on pourrait utiliser pour extraire et organiser l'information g√©ographique des titres et th√®mes d'une photographie : 
```raw
# R√¥le
Tu es un expert en extraction d'information g√©ographique dans des m√©tadonn√©es patrimoniales.

# T√¢che
Ta t√¢che est d'analyser un ensemble de m√©tadonn√©es textuelles d√©crivant une photographie et d'extraire la liste des entit√©s g√©ographiques pr√©sentes.

# R√®gles
R√®gle sp√©cifique : organise les entit√©s de la plus pr√©cise √† la plus g√©n√©rale.

Les m√©tadonn√©es √† analyser seront donn√©es dans le prochain input.
```

> ‚ÑπÔ∏è Notez qu'on ne donne ici **aucun exemple** de traitement. Cette strat√©gie "brute" s'appelle **0-shot prompting**, par opposition au **few-shot prompting** o√π l'on fournit quelques exemples dans le prompt.

On peut directement essayer ce prompt en utilisant le mod√®le "chatbot" grand-public de Mistral, disponible √† l'adresse https://chat.mistral.ai

> üé¨ Rendez-vous sur https://chat.mistral.ai, donnez le prompt ci-dessus au mod√®le, puis donnez le bloc de m√©tadonn√©es au d√©but de la section **Motivation**. Le mod√®le renvoit-il quelque chose qui vous semple directement utilisable dans un programme informatique ? Extrait-il toute l'information g√©ographique, nom du lieu "Au Soleil d'or" compris ? Que se passe t-il si vous donnez plusieurs fois de suite les m√™mes m√©tadonn√©es ?

Vous l'aurez compris, ce *prompt* est beaucoup trop na√Øf pour fonctionner correctement. 
Un LLM, aussi puissant qu'il est, n'est pas dans votre t√™te - il faut le guider beaucoup plus strictement.

Il manque plusieurs √©l√©ments critiques :

1. le mod√®le est libre d'ajouter du texte suppl√©mentaire dans sa r√©ponse ;
2. on ne contraint pas le format de r√©ponse ;
3. on explicite jamais la hi√©rarchie exacte √† extraire.

### Un *prompt* un peu moins na√Øf gr√¢ce au *few-shot prompting* 

√Ä l'heure actuelle, la mani√®re la plus simple de contraindre fortement un LLM √† produire ce que l'on souhaite consiste √† lui donner des exemples.
En effet, les LLMs sont extr√™mement guid√©s par les exemples, bien plus que par toute explication complexe qu'on pourrait leur fournir.
Cette strat√©gie qui consiste √† donner des exemples dans les instructions √† un mod√®le, avant d'envoyer les v√©ritables donn√©es √† traite est nomm√©e *few-shot prompting*.

Avec un seul exemple, on peut expliquer au mod√®le √† la fois le **format souhait√©** ainsi que **la hi√©rarchie spatiale** attendue de fa√ßon tr√®s simple : il suffit d'ajouter au *prompt* un extrait de m√©tadonn√©es √† traiter, ainsi que le r√©sultat attendu.

Disons que, lorsqu'on donne les m√©tadonn√©es d'une photo au LLM, on souhaite r√©cup√©rer une hi√©rarchie au format JSON, avec les niveaux suivants :
- Toponyme : le nom du lieu pr√©cis. S'il est pr√©sent, il est g√©n√©ralement dans le titre ;
- Adresse : adresse postale, donn√©e dans le titre √©galement ;
- Voie : dans le titre ou les th√®mes Rameau ;
- Ville : g√©n√©ralement dans les th√®mes Rameau ;
- Pays : dans les th√®mes Rameau √©galement, ou doit √™tre d√©duit.

Bien s√ªr, des champs peuvent √™tre absents, il s'agit d'une hi√©rarchie maximale.

Voici un exemple de m√©tadonn√©es, puis le r√©sultat d'extraction attendu au format JSON :
```raw
=== PHOTO : Au Bon Puits : Rue Michel Le Comte 36 (Disparu en 1904), [photographie] ===
Lien : http://data.bnf.fr/ark:/12148/cb40268303v#about
Th√®mes assign√©s:
 ‚Ä¢ ¬´ Vin -- Industrie et commerce ¬ª - altLabels : ¬´ Commerce vinicole ¬ª, ¬´ Industrie viticole ¬ª, ¬´ Commerce viticole ¬ª, ¬´ Production viticole ¬ª, ¬´ Production vinicole ¬ª, ¬´ Industrie vinicole ¬ª
 ‚Ä¢ ¬´ Paris (France) -- Rue Michel-le-Comte ¬ª - altLabels : ¬´ Rue Michel-le-Comte (Paris, France) ¬ª, ¬´ Michel-le-Comte, Rue (Paris, France) ¬ª
 ‚Ä¢ ¬´ Paris (France) ¬ª
 ‚Ä¢ ¬´ Enseignes ¬ª - altLabels : ¬´ Signes et indications ¬ª, ¬´ Enseignes commerciales ¬ª
 ‚Ä¢ ¬´ Ferronnerie d'art ¬ª - altLabels : ¬´ Ferronnerie architecturale ¬ª, ¬´ Ferrures ¬ª, ¬´ Serrurerie d'art ¬ª, ¬´ Ferronneries ¬ª, ¬´ Fer forg√©, Objets en ¬ª, ¬´ Fer ornemental ¬ª, ¬´ Ferronnerie d√©corative ¬ª, ¬´ Ferronnerie (architecture) ¬ª, ¬´ Fer forg√© ¬ª, ¬´ Objets en fer forg√© ¬ª
 ```

```json
{
	"toponyme": "Au Bon Puits",
	"adresse": "36 rue Michel Le Comte",
	"voie": "rue Michel Le Comte",
	"ville": "Paris",
	"pays": "France"
}
```

 > üé¨ Reprenez le prompt na√Øf, et am√©liorez-le en ajoutant une section "# Exemple" contenant cet exemple d'entr√©e et de sortie attendue.
 > R√©appliquez le traitement aux m√©tadonn√©es de la section **Motivation**.
 > Le r√©sultat devrait cette fois correspondre √† ce qu'on attend, un extrait de JSON contenant la hi√©rarchie g√©ographique extraite : 
 > ```json
 > { "toponyme": "Au Soleil d'or", "adresse": "84 rue Saint-Sauveur", "voie": "rue Saint-Sauveur", "ville": "Paris", "pays": "France" }
 > ```

 > üí° Donnez √† nouveau les m√™mes m√©tadonn√©es au LLM, plusieurs fois de suite. Est-ce que contenu et le r√©sultat est stable ?

Ce prompt produit des r√©sultats de qualit√© suffisante pour passer √† l'automatisation du traitement des m√©tadonn√©es gr√¢ce √† Mistral... et Python üôÇ

### Extraction structur√©e avec Mistral
 
 Il est possible d‚Äôinteragir avec les mod√®les de Mistral en Python gr√¢ce √† la biblioth√®que `mistralai`.

> üé¨ Installez d√®s maintenant le package avec :
> ```bash
> uv add mistralai
> ```

Pour apprendre √† utiliser cette biblioth√®que, int√©ressons-nous directement au cas d'usage qui nous int√©resse : **l'extraction d'information structur√©e** des dans textes.

> üé¨ Rendez-vous dans la documentation g√©n√©rale de Mistral, sur https://docs.mistral.ai, et cherchez dans le menu gauche l'entr√©e *Structured Output*.
> Lisez le texte de la  petite page "Structured Outputs" qui s'ouvre et r√©pondez √† ces deux questions :
> 1. Quel format structur√© est g√©r√© par les mod√®les Mistral ?
> 2. Quelles sont les deux possibilit√©s disponibles pour faire de l'extraction structur√©e ?

Commen√ßons par ne pas suivre les conseils de Mistral en choisissant le **JSON mode**, plus simple pour des d√©butants.

> üé¨ Rendez-vous sur la page de description de ce mode en suivant le lien [JSON: To enforce a JSON output](https://docs.mistral.ai/capabilities/structured_output/json_mode) sur la page *Structured Output*, ou en cliquant sur le sous-menu *JSON Mode* dans le panneau gauche.
> Lisez la courte documentation en faisant attention √† bien selectionner l'onglet "Python" pour voir l'exemple ... en Python  üòâ

> üé¨ Dans le r√©pertoire de la partie 2, cr√©ez un nouveau fichier de script Python nomm√© `extract_geohierarchy.py` puis collez-y le code Python donn√© sous la section *How to generate JSON consistently* de la page de documentation.
> Ajouter en fin de fichier la ligne suivante pour afficher la r√©ponse du mod√®le :
> ```python
> print(chat_response.choices[0].message.content)
> ```

Avant de pouvoir tester ce script, il faut d'abord renseigner votre **cl√© API Mistral**.
On voir dans l'extrait de code cette ligne : 
```python
api_key  =  os.environ["MISTRAL_API_KEY"]
```
Cela signifie que la valeur de la cl√© est lue depuis la **variable d'environnement** `MISTRAL_API_KEY`.
Il faut donc la d√©clarer dans votre session de terminal avant de pouvoir ex√©cuter le script.

> üé¨ Dans votre session de terminal, d√©clarez votre cl√© Mistral ainsi :
> ```bash
> export MISTRAL_API_KEY=votre_cl√©_mistral_ici
> ```
> Vous pouvez ensuite lancer le script Python :
> ```bash
> uv run extract_geohierarchy.py
> ```

Vous devriez obtenir le r√©sultat suivant :

```bash
‚ùØ uv run ./extract_geohierarchy.py
{
  "meal": "Boeuf Bourguignon",
  "ingredients": [
    "beef",
    "red wine (Burgundy)",
    "onions",
    "carrots",
    "garlic",
    "mushrooms",
    "bacon",
    "bouquet garni",
    "beef stock",
    "butter",
    "flour",
    "salt",
    "pepper"
  ]
}
```