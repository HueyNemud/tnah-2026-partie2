
#  ğŸ™¤ **PARTIE 2** ğŸ™§

  

#  Extraction structurÃ©e des indices gÃ©ographiques dans les mÃ©tadonnÃ©es des photographies d'[EugÃ¨ne Atget](https://fr.wikipedia.org/wiki/Eug%C3%A8ne_Atget)

  
  

ğŸ™‘ Au-delÃ  de son volume, l'Å“uvre d'EugÃ¨ne Atget frappe par la mÃ©ticulositÃ© de son classement. VÃ©ritable archiviste de son propre travail, lâ€™auteur a systÃ©matiquement indexÃ© ses clichÃ©s, les structurant en sÃ©ries et en albums thÃ©matiques. Chaque clichÃ© est dotÃ© d'un titre dÃ©crivant son sujet et sa localisation, souvent trÃ¨s prÃ©cisÃ©ment.

  

Ces titres, systÃ©matiquement relevÃ©s et transcrits, font parti des mÃ©tadonnÃ©es associÃ©es Ã  chaque photographie. Les archivistes ne se sont cependant pas arrÃªtÃ© lÃ  et ont enrichi la description structurÃ©e de chaque clichÃ© avec des thÃ¨mes issus du thÃ©saurus Rameau.

  

La richesse gÃ©ographique de ces mÃ©tadonnÃ©es permet aujourd'hui d'envisager une cartographie du fonds dans lâ€™espace parisien. Cette approche, image par image, offrirait un parcours inÃ©dit au cÅ“ur de la capitale et renouvellerait notre regard sur lâ€™Å“uvre du photographe.

  

ğŸ™‘ **Rappel**. Dans la [partie 1](https://github.com/HueyNemud/tnah-2026-partie1), nous avons explorÃ© le graphe de connaissances de la bibliothÃ¨que nationale de France, publiÃ© sur data.bnf.fr, analysÃ© le schÃ©ma de mÃ©tadonnÃ©es *WEMI* utilisÃ© pour structurer les mÃ©tadonnÃ©es descriptives des Å“uvres, et extrait pour chaque photographie un graphe RDF contenant les mÃ©tadonnÃ©es la dÃ©crivant. Dans le chapitre 4, les graphes individuels des photographies ont Ã©tÃ© enregistrÃ©s au format Turtle sur le disque, dans un dossier nommÃ© `photographies/`

##  ğŸ™¤ Objectifs

Cette seconde partie guide la mise en place d'un processus d'extraction de l'information gÃ©ographique contenue dans les mÃ©tadonnÃ©es des photographies d'EugÃ¨ne Atget rÃ©coltÃ©es dans la premiÃ¨re partie.

Elle se dÃ©compose en deux Ã©tapes :

1. D'abord enrichir les graphes de mÃ©tadonnÃ©es des photographies avec les **thÃ¨mes Rameau** qui leurs sont associÃ©s, afin d'obtenir le plus possible d'indications gÃ©ographiques. Cette premiÃ¨re Ã©tape est l'occasion d'un **exercice de lecture de code** Python.
  
2. Ensuite, **extraire l'information gÃ©ographique pertinente** dans le titre et des thÃ¨mes de chaque photographie pour obtenir un ensemble d'indications de localisation qui pourront Ãªtre utilisÃ© pour placer la photographie dans Paris et ses alentours. Cette tÃ¢che de **traitement automatique du langage naturel** sera rÃ©alisÃ© avec un **grand modÃ¨le de langage gÃ©nÃ©ratif**.

Ce chapitre 2 porte sur la **seconde Ã©tape**.

LÃ©gende des pictogrammes utilisÃ©s :

| Picto. | LÃ©gende |
|  ------  |  -----------------------------------------  |
| ğŸ¬ | Action Ã  rÃ©aliser : Ã  vous de jouer ! |
| ğŸ’¡ | Suggestion d'action complÃ©mentaire |
| âš ï¸ | Avertissement |
| â„¹ï¸ | Information supplÃ©mentaire ou astuce |
| ğŸ“š | Ressources : documentation, article, etc. |

<hr/>

##  ğŸ™¤ Chapitre 2 : extraction structurÃ©e de l'information gÃ©ographique contenue dans les mÃ©tadonnÃ©es des photographies

**âš ï¸ PrÃ©requis**
- Avoir terminÃ© le chapitre 1 de la partie 2 et exÃ©cutÃ© le script Python `fetch_themes.py` pour enrichir tous les graphes de photographies dans le dossier `photographies/` avec les labels de leurs thÃ¨mes Rameau.
- le dossier `photographies_avec_themes/` doit exister et doit contenir les **sÃ©rialisations Turtle des graphes de chaque photographie enrichies** de leurs thÃ¨mes Rameau.

###  Motivation
Notre but est de rÃ©ussir Ã  placer chaque photographie d'un lieu sur une carte, Ã  l'endroit oÃ¹ se trouvait ce lieu.
Pour cela il faut **gÃ©ocoder** la photographie, c'est Ã  dire lui lui associer des **coordonnÃ©es gÃ©ographiques**, en lâ€™occurrence celles du lieu pris en photo par Atget.

On a besoin pour cela de glaner **l'information gÃ©ographique** qui se trouve dans les mÃ©tadonnÃ©es d'une photographie, ce qui - on l'espÃ¨re - fournira assez d'indices gÃ©ographiques sur l'emplacement de cette photographie.

Dans le chapitre 1, on a vu que le **titre** de la photographie et ses **thÃ¨mes Rameau** contenaient des indices gÃ©ographiques.

Parce que les grands modÃ¨les de langages sont conÃ§us pour exploiter -entre autre- du texte, nous n'allons pas travailler directement avec les graphes de connaissance des photographies, mais avec une forme "sÃ©rialisÃ©e" en texte : leur rapport d'enrichissement produit par la fonction `build_summary_report()` dans le script `fetch_themes.py`.

Voici par exemple le rapport sur l'enrichissement de la photographie du [Cabaret du Soleil d'or](https://gallica.bnf.fr/ark:/12148/btv1b10506998t#)  :
```raw
=== PHOTO : Au Soleil d'or : 84 [quatre-vingt-quatre] Rue S.t Sauveur (ModifiÃ©), [photographie] ===
Lien : http://data.bnf.fr/ark:/12148/cb40268281c#about
ThÃ¨mes assignÃ©s:
â€¢ Â« Dans l'art Â» - altLabels : Â« ReprÃ©sentation dans l'art Â», Â« Dans la sculpture Â», Â« Dans la peinture Â», Â« ReprÃ©sentation iconographique Â», Â« Dans les arts graphiques Â»
â€¢ Â« CafÃ©s Â» - altLabels : Â« CafÃ©s-bars Â», Â« DÃ©bits de boissons Â», Â« Estaminets Â», Â« Brasseries (cafÃ©s) Â», Â« Zincs (cafÃ©s) Â», Â« Bistrots Â», Â« CafÃ©s publics Â», Â« CafÃ©s (Ã©tablissements) Â», Â« Bars Â»
â€¢ Â« Paris (France) Â»
â€¢ Â« Paris (France) -- Rue Saint-Sauveur Â» - altLabels : Â« Rue Saint-Sauveur (Paris, France) Â», Â« Saint-Sauveur, Rue (Paris, France) Â»
â€¢ Â« Enseignes Â» - altLabels : Â« Signes et indications Â», Â« Enseignes commerciales Â»
â€¢ Â« Ferronnerie d'art Â» - altLabels : Â« Serrurerie d'art Â», Â« Fer forgÃ©, Objets en Â», Â« Fer ornemental Â», Â« Ferronnerie architecturale Â», Â« Ferrures Â», Â« Ferronneries Â», Â« Ferronnerie dÃ©corative Â», Â« Fer forgÃ© Â», Â« Objets en fer forgÃ© Â», Â« Ferronnerie (architecture) Â»
â€¢ Â« Soleil Â» - altLabels : Â« Physique solaire Â»
```
  
Une simple lecture de ce rapport permet de repÃ©rer un certain nombre d'indices gÃ©ographiques, qu'on peut intuitivement organiser par granularitÃ© pour former une **hiÃ©rarchie spatiale** qui dÃ©crit Ã  plusieurs Ã©chelles l'emplacement du lieu dans Paris :
```raw
ğŸ“ France [pays]
	â””â”€â”€ ğŸ™ï¸ Paris [ville]
		â””â”€â”€ ğŸ›£ï¸ rue Saint-Sauveur [rue]
			â””â”€â”€ ğŸ  nÂ° 84 rue Saint-Sauveur [adresse]
				â””â”€â”€ â˜€ï¸ Â« Au Soleil d'or Â» [enseigne / toponyme]
```

Cette opÃ©ration en apparence simple enchaÃ®ne plusieurs taches qui mobilisent des capacitÃ©s cognitives humaines typiquement difficiles Ã  transfÃ©rer sous la forme de programme informatique : 
- **identifier** l'information gÃ©ographique dans le titre et les thÃ¨mes nÃ©cessite de comprendre la langue franÃ§aise, de connaitre la gÃ©ographie parisienne, ...
- **extraire** cette information gÃ©ographique nÃ©cessite de rÃ©ussir Ã  la sÃ©parer de son contexte et au besoin Ã  la rÃ©interprÃ©ter, par exemple pour que "84 [quatre-vingt-quatre] Rue S.t Sauveur"  soit compris comme l'adresse du nÂ°84 rue Saint-Sauveur".
- **organiser** cette information de maniÃ¨re hiÃ©rarchique implique Ã©galement une connaissance implicite importante: comment fonctionne une adresse, comment les humains structurent hiÃ©rarchiquement les lieux, etc.

RÃ©aliser cet enchaÃ®nement de tÃ¢ches avec un ordinateur est un cas typique de **traitement automatique du langage naturel**.
On pourrait imaginer la programmer naÃ¯vement sous la forme d'une chaÃ®ne de traitement, en utilisant par exemple des techniques Ã  base de rÃ¨gles, mais cela serait Ã  la fois trÃ¨s fastidieux et trÃ¨s fragile aux variations dans les formes de description des mÃ©tadonnÃ©es.

Aujourdâ€™hui, utiliser un **grand modÃ¨le de langage (LLMs) gÃ©nÃ©ratifs** pour rÃ©aliser cet enchaÃ®nement de taches en **une seule Ã©tape** est gÃ©nÃ©ralement l'approche la plus efficace. 

Nous allons donc utiliser un LLM pour **extraire et organiser hiÃ©rarchiquement l'information gÃ©ographique** contenue dans le titre et les thÃ¨mes Rameau des photographes.

Cette expÃ©rimentation sera rÃ©alisÃ©e avec les grands modÃ¨les de langages de **[Mistral AI](https://mistral.ai/fr)**.

###  Premier essai naÃ¯f
En tant qu'utilisateur, le fonctionnement d'un modÃ¨le de langage est simple : c'est modÃ¨le statistique qui prend en entrÃ©e une information - par exemple un texte -, et gÃ©nÃ¨re un nouveau texte qui est conditionnÃ© par le contenu informationnel de lâ€™entrÃ©e. 

Ces modÃ¨les sont extrÃªmement performants pour rÃ©aliser de nombreuses taches de traitement automatique du langage naturel, car leur capacitÃ© d'attention et les connaissance stockÃ©es dans leur mÃ©moire (apprise) les rendent capables de traitements complexes nÃ©cessitant des connaissances implicites importantes.

Ces capacitÃ©s d'analyse sont maintenant bien connues et les LLM sont explicitement entraÃ®nÃ©s pour Ãªtre utilisÃ©s comme outils de traitement que l'on peut guider Ã  l'aide d'**instructions** (le *prompt*).

Testons les capacitÃ©s du LLM de Mistral pour extraire la hiÃ©rarchie gÃ©ographique du lieu dÃ©crit dans les mÃ©tadonnÃ©es d'une photographie.
CommenÃ§ons avec le mode d'accÃ¨s le plus grand public au LLM principal de Mistral :  le chatbot _Le Chat_.

Essayons de faire extraire au LLM la hiÃ©rarchie gÃ©ographique parsemÃ©e dans le rapport sur la photographie du [abaret du Soleil d'or](https://gallica.bnf.fr/ark:/12148/btv1b10506998t#) donnÃ© dans la section **Motivation**.

Pour guider un LLM, il faut un *prompt* dÃ©crivant la tache qu'il doit rÃ©aliser.
S'il n'existe pas de "bible" de la rÃ©daction de prompt, tous les LLMs sont entraÃ®nÃ©s pour comprendre des *prompts* dont structure gÃ©nÃ©rale est la suivante :

> a. Assigner un rÃ´le au modÃ¨le pour la tache.
> b. DÃ©crire la tÃ¢che Ã  rÃ©aliser
> c. Si nÃ©cessaire, donner des rÃ¨gles spÃ©cifiques pour gÃ©rer les cas complexes, ambigus, etc.

Voici un premier *prompt* trÃ¨s simple qu'on peut utiliser pour extraire la hiÃ©rarchie gÃ©ographique Ã  partir d'un rapport d'enrichissement de photographie :

```raw
# RÃ´le
Tu es un expert en extraction d'information gÃ©ographique dans des mÃ©tadonnÃ©es patrimoniales.

# TÃ¢che
Ã€ partir d'un rÃ©sumÃ© descriptif d'une photographie ancienne, tu dois :
1. identifier les entitÃ©s gÃ©ographiques qui renseignent sur **la localisation du sujet de la photographie** dans l'espace ;
2. lister ces entitÃ©s les uns aprÃ¨s les autres.

# RÃ¨gles
- les entitÃ©s doivent Ãªtre triÃ©e de la plus prÃ©cise Ã  la plus gÃ©nÃ©rale.

Le rÃ©sumÃ© Ã  traiter sera donnÃ© dans le prochain input.
```

> â„¹ï¸ Notez qu'on ne donne ici **aucun exemple** de traitement. Cette stratÃ©gie fondÃ©e uniquement sur des rÃ¨gles s'appelle **0-shot prompting**.

> ğŸ¬ Rendez vous sur https://chat.mistral.ai/chat et donnez ce *prompt* au *chatbot*. Donnez ensuite le rapport d'enrichissement sur le cabaret du Soleil d'Or.

Vous devriez constater que mÃªme avec un *prompt* grossier, le modÃ¨le fournit une rÃ©ponse dÃ©jÃ  trÃ¨s satisfaisante contenant une partie de la hiÃ©rarchie souhaitÃ©e.
Par exemple :
```raw
Pour cette photographie, les entitÃ©s gÃ©ographiques permettant de localiser
 le sujet sont les suivantes :
1.  84 Rue Saint-Sauveur**
2.  Rue Saint-Sauveur (Paris, France)**
3.  Paris (France)
Si vous avez besoin d'une autre analyse, n'hÃ©sitez pas Ã  me le demander !
```
  > â„¹ï¸ Du fait de la nature stochastique d'un LLM, sa rÃ©ponse peut varier.

Toutefois, le *prompt* contraint trÃ¨s peu la rÃ©ponse du LLM : pas de format imposÃ©, pas de liste de niveau hiÃ©rarchiques Ã  extraire.
LaissÃ© libre, le modÃ¨le a "dÃ©cidÃ©" d'organiser la hiÃ©rarchie en liste numÃ©rotÃ©e, d'ajouter des commentaires, ignorer le toponyme ou ajouter des complÃ©ments entre parenthÃ¨ses.

Cela ne pose pas de problÃ¨mes de comprÃ©hension Ã  un humain, mais n'oublions pas que le notre but est d'extraire une hiÃ©rarchie exploitable dans un processus **automatique** de gÃ©ocodage.
Il faut donc que la sortie du LLM ne soit pas du simple texte, mais un texte formatÃ©, standardisÃ©, comprÃ©hensible par un programme.
C'est ce qu'on appelle de  **l'extraction structurÃ©e** d'information.

###  Extraction structurÃ©e avec _Le Chat_
Pour produire une rÃ©ponse dans un format prÃ©cis, interprÃ©table informatiquement et qui contienne tous les niveaux hiÃ©rarchiques souhaitÃ©s, nous devons guider bien plus strictement le modÃ¨le.

Une maniÃ¨re simple et particuliÃ¨rement efficace consiste Ã  ajouter au *prompt* au moins un exemple de rapport et la sortie attendue.
Cette stratÃ©gie de guidage contextuel par l'exemple se nomme *few-shot prompting*.
  > â„¹ï¸ On trouve aussi parfois le terme de *few-shot training*, mais cette appellation porte Ã  confusion et tend Ã  disparaÃ®tre. Si les rÃ©seaux de neurones profonds sont bien entraÃ®nÃ©s avec des exemples, cela n'a rien a voir avec le *prompting*. Les exemples dans le *prompt* font seulement partie du contexte accessible au modÃ¨le durant la gÃ©nÃ©ration du nouveau texte - cela guide son attention courante et son comportement, mais il n'apprend rien et ne stocke aucune nouvelle connaissance dans sa mÃ©moire.
  
A priori, tout format structurÃ© est envisageable pour la hiÃ©rarchie infÃ©rÃ©e.
Cependant, les LLMs sont gÃ©nÃ©ralement plus performants pour produire du JSON, parce qu'ils ont Ã©tÃ© entraÃ®nÃ©s pour les taches d'extraction structurÃ©e spÃ©cifiquement avec ce format.

Voici une reprÃ©sentation JSON possible de la hiÃ©rarchie donnÃ©e en **motivation** : 
```json
{
	"toponyme": "Au Soleil d'Or",
	"adresse": "84 rue Saint-Sauveur",
	"voie" : "rue Saint-Sauveur",
	"ville": "Paris",
	"pays": "France"
}
```

> ğŸ¬ Modifiez le *prompt* d'extraction pour : 
> 1. InsÃ©rer une nouvelle rÃ¨gle : "- la rÃ©ponse doit contenir **uniquement** du JSON suivant le schÃ©ma donnÃ© en exemple."
> 2. Ajouter une quatriÃ¨me section nommÃ©e  `# Exemple` formatÃ©e ainsi 
```raw
# Exemple
**RÃ©sumÃ© descriptif **
<Ajoutez le rapport de la section **motivation** sur le cabaret du Soleil d'Or>

**RÃ©ponse JSON**
<Ajoutez ici la reprÃ©sentation JSON donnÃ©e ci-dessus>
```
> CrÃ©ez un **Nouveau Chat** pour ne pas biaiser Mistral avec vos prÃ©cÃ©dents messages, puis donnez le nouveau *prompt*.

Pour tester les performances de ce nouveau *prompt* nous devons utiliser un nouveau rapport d'enrichissement puisque celui du cabaret du Soleil d'Or est dÃ©jÃ  donnÃ© comme exemple.

> ğŸ¬ Testez avec le rapport du "Bon Puits" :
```raw
=== PHOTO : Au Bon Puits : Rue Michel Le Comte 36 (Disparu en 1904), [photographie] ===
Lien : http://data.bnf.fr/ark:/12148/cb40268303v#about
ThÃ¨mes assignÃ©s:
â€¢ Â« Vin -- Industrie et commerce Â» - altLabels : Â« Commerce vinicole Â», Â« Industrie viticole Â», Â« Commerce viticole Â», Â« Production viticole Â», Â« Production vinicole Â», Â« Industrie vinicole Â»
â€¢ Â« Paris (France) -- Rue Michel-le-Comte Â» - altLabels : Â« Rue Michel-le-Comte (Paris, France) Â», Â« Michel-le-Comte, Rue (Paris, France) Â»
â€¢ Â« Paris (France) Â»
â€¢ Â« Enseignes Â» - altLabels : Â« Signes et indications Â», Â« Enseignes commerciales Â»
â€¢ Â« Ferronnerie d'art Â» - altLabels : Â« Ferronnerie architecturale Â», Â« Ferrures Â», Â« Serrurerie d'art Â», Â« Ferronneries Â», Â« Fer forgÃ©, Objets en Â», Â« Fer ornemental Â», Â« Ferronnerie dÃ©corative Â», Â« Ferronnerie (architecture) Â», Â« Fer forgÃ© Â», Â« Objets en fer forgÃ© Â»
```
> Le modÃ¨le doit rÃ©pondre la hiÃ©rarchie JSON suivante : 
```json
{
	"toponyme": "Au Bon Puits",
	"adresse": "36 rue Michel-Le-Comte",
	"voie": "rue Michel-Le-Comte",
	"ville": "Paris",
	"pays": "France"
}
```
> C'est mieux, non ? ğŸ™‚ On obtient le format attendu, avec tous les niveaux hiÃ©rarchiques souhaitÃ©s, triÃ©s dans le bon ordre.

Voyons maintenant comment automatiser ce traitement en Python grÃ¢ce Ã  la bibliothÃ¨que `mistralai` publiÃ©e par Mistral.

###  Extraction structurÃ©e par LLM en Python avec `mistralai`
CommenÃ§ons par installer la bibliothÃ¨que avec `uv`.
> ğŸ¬ Dans un terminal, placez vous dans le dossier de travail `tnah-2026-partie2` et exÃ©cutez
```bash
uv add mistralai
```
CrÃ©ons ensuite un fichier de script Python qui contiendra le processus complet d'extraction structurÃ©e.

> ğŸ¬ Dans le mÃªme dossier, crÃ©ez un nouveau fichier Python nommÃ© `structured_extraction.py`. Par exemple depuis le terminal :
```bash
touch structured_extraction.py
```

La [documentation gÃ©nÃ©rale de Mistral](https://docs.mistral.ai) prÃ©sente et illustre par l'exemple comment utiliser la bibliothÃ¨que `mistralai` pour faire de l'extraction structurÃ©e.

> ğŸ¬ Rendez-vous dans la documentation de Mistral, sur https://docs.mistral.ai, et cherchez dans le menu gauche l'entrÃ©e *Structured Outputs* puis *JSON Mode*.
> Lisez la ligne de prÃ©sentation. Comprenez-vous quelle est la spÃ©cificitÃ© de ce *JSON Mode* ?

La page de documentation donne un exemple complet d'interaction avec le modÃ¨le LLM `
mistral-large-latest`  hÃ©bergÃ© sur leurs serveurs.

> ğŸ“š `mistral` est la famille de modÃ¨le, `mistral-large` est le plus modÃ¨le ayant le plus de paramÃ¨tres, gÃ©nÃ©ralement le plus puissant. Le suffixe  `-latest` dÃ©signe la version la plus rÃ©cente disponible.

> ğŸ¬ Copiez cet exemple dans le fichier `structured_extraction.py` et :
```python
# 1. Commentez **momentanÃ©ment la ligne suivante 
#api_key = os.environ["MISTRAL_API_KEY"]
# Remplacez la par :
api_key = VOTRE_CLÃ‰_MISTRAL_ICI 

... # le reste de l'exemple est inchangÃ©

# 2. Ajoutez Ã  la fin du script la ligne suivante pour afficher le rÃ©sultat 
# de la requÃªte envoyÃ©e Ã  Mistral :
print(chat_response.choices[0].message.content)
```
> ğŸ¬ ExÃ©cutez le script et vÃ©rifiez que le rÃ©sultat est le mÃªme que sur la page de documentation.
```bash
uv run structured_extraction.py
```
Nous voilÃ  avec un script minimaliste mais fonctionnel pour utiliser le LLM `mistral-large` de maniÃ¨re programmatique.


> â„¹ï¸ Notez que c'est la prÃ©sence du paramÃ¨tre `response_format = {"type": "json_object"}` dans l'appel Ã  `client.chat.complete()` qui **contraint** le modÃ¨le Ã  produire un rÃ©sultat JSON. Sans lui le modÃ¨le se comporterait exactement comme le chatbot "Le Chat", c'est Ã  dire sans aucune garantie stricte de produire un JSON correct.

###  Extraction d'une hiÃ©rarchie gÃ©ographique avec Mistral
Adaptons maintenant le script pour notre tache d'extraction de hiÃ©rarchie gÃ©ographique !ğŸ‘

Dans l'exemple, aprÃ¨s avoir crÃ©Ã© un client `Mistral` reprÃ©sentant la connexion au LLM distant, on dÃ©finit la variable `messages` qui est une liste de messages Ã  envoyer au modÃ¨le.
Chaque message est reprÃ©sentÃ© par un dictionnaire contenant deux clÃ©s : `"content"` et `"role"` . 
La clÃ© *content* est triviale : c'est le contenu du message qui est donnÃ© au modÃ¨le.
La clÃ© *role* peut prendre plusieurs valeurs; deux nous intÃ©ressent ici :
- `"role": "user"` : le LLM va considÃ©rer que le message est celui d'un utilisateur, et y porter une attention passagÃ¨re. C'est typiquement le rÃ´le adÃ©quat pour envoyer le **rapport d'enrichissement** Ã  traiter.
- `"role": "system"` : permet de dÃ©finir un **system prompt**, c'est Ã  dire une instruction gÃ©nÃ©rale que le modÃ¨le va conserver Ã  "l'esprit" toute la durÃ©e de l'Ã©change. Ce rÃ´le est spÃ©cialement adaptÃ© pour donner les **instructions de traitement** au modÃ¨le.

> ğŸ¬ Modifiez les messages stockÃ©s dans la variable `messages` pour :
> 1. Donner dans un premier message avec le rÃ´le **system** le prompt *few-shot* crÃ©Ã© dans la section **Extraction structurÃ©e avec _Le Chat_**
> 2. Donner dans un second message avec le rÃ´le **user** le rapport du "Bon Puits".
> 
> ExÃ©cutez Ã  nouveau le script et vÃ©rifiez qu'il affiche bien la hiÃ©rarchie JSON dans le terminal !
 
###  Automatisation de l'extraction structurÃ©e
Jusqu'ici, nous avons assignÃ© manuellement le rapport d'enrichissement Ã  traiter.
Allons un cran plus loin en utilisant les fonctions dÃ©finies dans `fetch_themes.py`, vues dans le chapitre 1, pour crÃ©er dynamiquement un rapport et l'envoyer Ã  Mistral.

Nous avions utilisÃ© `fetch_themes.py` comme un script exÃ©cutable, mais nous pouvons Ã©galement l'utiliser comme un **module python** dont on peut importer les fonctions.

> ğŸ¬ Importez dans `structured_extraction.py` les fonctions `import_turtle_file()` `build_summary_report()` du fichier `fetch_themes.py` :
```python
from fetch_themes import build_summary_report, fetch_themes
```

Nous pouvons ensuite utiliser ces fonctions pour lire un graphe de photographie et crÃ©er son rapport d'enrichissement.

> ğŸ¬ AprÃ¨s la crÃ©ation du client Mistral, utilisez les deux fonctions importÃ©es pour lire un fichier de graphe enrichi de votre choix depuis le dossier `photographies_avec_themes/` et crÃ©er son rapport d'enrichissement et : 
> 1. Stockez ce rapport dans un variable nommÃ©e `report`
> 2. Affichez la avec `print()`.
> 3. Remplacez dans la dÃ©claration des messages le contenu du message de rÃ´le *user* par la variable `report`
> 4. ExÃ©cutez le script pour vÃ©rifier qu'il traite bien le fichier de graphe que vous avez choisi !

###  Traitement en masse des graphes de photographie
Reste une ultime Ã©tape : **traiter tous les graphes** et **enregistrer le rÃ©sultat JSON sur le disque** pour la phase suivante de gÃ©ocodage.

Il manque pour cela deux Ã©lÃ©ments :
1. une boucle pour traiter chaque fichier de graphe du dossier  `photographies_avec_themes/` ;
2. une fonction d'enregistrement de la rÃ©ponse du modÃ¨le en JSON.

CommenÃ§ons par le premier Ã©lÃ©ment, oÃ¹ nous pouvons reprendre exactement la mÃªme logique que dans le script `fetch_themes.py`. N'hÃ©sitez pas Ã  "piocher" dans ce script pour vous aider.

> ğŸ¬ Ajoutez l'import de la classe `Path` de `pathlib`:
```python
from pathlib import Path
```
> ğŸ¬ CrÃ©ez ensuite une variable `DIR` qui contient le chemin vers le dossier `photographies_avec_themes/`, puis rÃ©cupÃ©rez la liste de tous les fichiers Turtle dans ce dossier.
Notez que le dossier cible pour enregistrement les fichiers JSONs sera le mÃªme, pas besoin donc de distinguer `INPUT_DIR` et `OUTPUT_DIR`.
```python
DIR = Path(__file__).parent  /  "photographies_avec_themes"
turtle_files  =  list(input_dir.glob("*.ttl"))
```

> ğŸ¬ Placez les appels Ã  `import_turtle_file()` et `build_summary_report()`, la dÃ©claration des messages, l'appel au modÃ¨le Mistral et l'instruction `print()` finale Ã  l'intÃ©rieur d'une boucle qui itÃ¨re sur chaque fichier de graphe :
```python
for turtle_file in turtle_files:	
	print(f"Traitement de {turtle_file}...")
	data  =  import_turtle_file(turtle_file)
	report  =  build_summary_report(data)
	... # La suite
```
> âš ï¸ Attention Ã  l'indentation !	

> ğŸ¬  Testez en exÃ©cutant le traitement pour **1 seul graphe** en utilisant le mÃ©canisme de *slicing* 
```python
for turtle_file in turtle_files[:1]:
	... # La suite
```


> ğŸ’¡ Pour un code plus lisible, vous pouvez dÃ©placer le prompt systÃ¨me dans une constante `SYSTEM_PROMPT` placÃ©e en dÃ©but de script.

> ğŸ¬ En dÃ©but de script, ajoutez la dÃ©claration de la fonction suivante, qui prend en paramÃ¨tre le chemin vers le graphe `.ttl` stockÃ© dans la variable de boucle `turtle_file` ainsi que la rÃ©ponse du modÃ¨le Mistral `chat_response` et sauvegarde le rÃ©sultat en JSON sur le disque dur Ã  cotÃ© du fichier ` :
```python 
def  save_to_json(chat_response,  turtle_file):
	"""Sauvegarde la rÃ©ponse de Milstra en JSON Ã  cotÃ© du fichier `turtle_file`."""
	import  json # <-- Import Ã  dÃ©placer en entÃªte du script pour suivre les bonnes 	output_file  =  turtle_file.with_suffix(".json")
	data  =  chat_response.choices[0].message.content
	with  open(output_file,  "w",  encoding="utf-8")  as  f:
		json.dump(data,  f,  ensure_ascii=False,  indent=4)
```
>ğŸ¬  Appelez cette fonction juste aprÃ¨s l'instruction `print(chat_response.choices[0].message.content)` en lui passant la rÃ©ponse du modÃ¨le et le chemin vers le fichier Turtle du graphe.
```python 
for turtle_file in turtle_files[:1]:
	... # contenu de la boucle
	print(chat_response.choices[0].message.content)
	save_to_json(chat_response,  turtle_file)
```
>ğŸ¬ ExÃ©cutez de nouveau le script puis **vÃ©rifiez** que le dossier `photographies_avec_themes/` contient bien un fichier JSON contenant la hiÃ©rarchie extraite pour le graphe choisi !

Dans sa version gratuite, Mistral **impose** une limite de **une requÃªte maximum par seconde**.
Nous ***devons** donc forcer ce dÃ©lai pour Ã©viter que les requÃªtes soient rejetÃ©es par Mistral.
Une maniÃ¨re simpliste mains fonctionnelle consiste Ã  obliger le script Ã  attendre un certain temps aprÃ¨s chaque boucle, grÃ¢ce Ã  la fonction `sleep(n_seconds)` de la bibliothÃ¨que  `time`.

>ğŸ¬ Ajoutez l'import de `time` en entÃªte du script :
```python 
import time
```
>ğŸ¬ Forcez le script Ã  attendre par exemple 1.5 seconde aprÃ¨s avoir enregistrÃ© la hiÃ©rarchie du graphe courant en JSON, avant de passer au fichier suivant : 
```python 
for turtle_file in turtle_files[:1]:
	... # contenu de la boucle
	print(chat_response.choices[0].message.content)
	save_to_json(chat_response,  turtle_file)
	time.sleep(1.5)
```
>ğŸ¬ Vous pouvez maintenant retirer le *slicing* sans crainte puis exÃ©cuter enfin l'extraction structurÃ©e pour toutes les photographies ! ğŸ¥³

>ğŸ’¡ Observez les rÃ©sultats d'extraction qui s'affichent au fur et Ã  mesure sur le terminal.
> Est-ce que le schÃ©ma que l'on a fixÃ© est toujours respectÃ© par le LLM ? 
> Discutons-en ! ğŸ’¬

###  ğŸ Fin du chapitre 2

FÃ©licitations, vous voici Ã©quipÃ© avec un script fonctionnel **d'extraction structurÃ©e** utilisant un LLM de Mistral ! ğŸ‰

Une fois le traitement effectuÃ© sur tous les graphes, chaque fichier `.ttl` devrait avoir son fichier compagnon `.json` dÃ©crivant la hiÃ©rarchie gÃ©ographique de la photographie. 

Vous avez maintenant toutes les donnÃ©es utiles pour **gÃ©ocoder** et **cartographier** le font Atget - ce qu'on verra dans la **partie 3** ! 
