<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Welcome file</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="🙤-partie-2-🙧">🙤 <strong>PARTIE 2</strong> 🙧</h1>
<h1 id="extraction-structurée-des-indices-géographiques-dans-les-métadonnées-des-photographies-deugène-atget">Extraction structurée des indices géographiques dans les métadonnées des photographies d’<a href="https://fr.wikipedia.org/wiki/Eug%C3%A8ne_Atget">Eugène Atget</a></h1>
<p>🙑 Au-delà de son volume, l’œuvre d’Eugène Atget frappe par la méticulosité de son classement. Véritable archiviste de son propre travail, l’auteur a systématiquement indexé ses clichés, les structurant en séries et en albums thématiques. Chaque cliché est doté d’un titre décrivant son sujet et sa localisation, souvent très précisément.</p>
<p>Ces titres, systématiquement relevés et transcrits, font parti des métadonnées associées à chaque photographie. Les archivistes ne se sont cependant pas arrêté là et ont enrichi la description structurée de chaque cliché avec des thèmes issus du thésaurus Rameau.</p>
<p>La richesse géographique de ces métadonnées permet aujourd’hui d’envisager une cartographie du fonds dans l’espace parisien. Cette approche, image par image, offrirait un parcours inédit au cœur de la capitale et renouvellerait notre regard sur l’œuvre du photographe.</p>
<p>🙑 <strong>Rappel</strong>. Dans la <a href="https://github.com/HueyNemud/tnah-2026-partie1">partie 1</a>, nous avons exploré le graphe de connaissances de la bibliothèque nationale de France, publié sur <a href="http://data.bnf.fr">data.bnf.fr</a>, analysé le schéma de métadonnées <em>WEMI</em> utilisé pour structurer les métadonnées descriptives des œuvres, et extrait pour chaque photographie un graphe RDF contenant les métadonnées la décrivant. Dans le chapitre 4, les graphes individuels des photographies ont été enregistrés au format Turtle sur le disque, dans un dossier nommé <code>photographies/</code></p>
<h2 id="🙤-objectifs">🙤 Objectifs</h2>
<p>Cette seconde partie guide la mise en place d’un processus d’extraction de l’information géographique contenue dans les métadonnées des photographies d’Eugène Atget récoltées dans la première partie.</p>
<p>Elle se décompose en deux étapes :</p>
<ol>
<li>
<p>D’abord enrichir les graphes de métadonnées des photographies avec les <strong>thèmes Rameau</strong> qui leurs sont associés, afin d’obtenir le plus possible d’indications géographiques. Cette première étape est l’occasion d’un <strong>exercice de lecture de code</strong> Python.</p>
</li>
<li>
<p>Ensuite, <strong>extraire l’information géographique pertinente</strong> dans le titre et des thèmes de chaque photographie pour obtenir un ensemble d’indications de localisation qui pourront être utilisé pour placer la photographie dans Paris et ses alentours. Cette tâche de <strong>traitement automatique du langage naturel</strong> sera réalisé avec un <strong>grand modèle de langage génératif</strong>.</p>
</li>
</ol>
<p>Ce chapitre 2 porte sur la <strong>seconde étape</strong>.</p>
<p>Légende des pictogrammes utilisés :</p>

<table>
<thead>
<tr>
<th>Picto.</th>
<th>Légende</th>
</tr>
</thead>
<tbody>
<tr>
<td>🎬</td>
<td>Action à réaliser : à vous de jouer !</td>
</tr>
<tr>
<td>💡</td>
<td>Suggestion d’action complémentaire</td>
</tr>
<tr>
<td>⚠️</td>
<td>Avertissement</td>
</tr>
<tr>
<td>ℹ️</td>
<td>Information supplémentaire ou astuce</td>
</tr>
<tr>
<td>📚</td>
<td>Ressources : documentation, article, etc.</td>
</tr>
</tbody>
</table><hr>
<h2 id="🙤-chapitre-2--extraction-structurée-de-linformation-géographique-contenue-dans-les-métadonnées-des-photographies">🙤 Chapitre 2 : extraction structurée de l’information géographique contenue dans les métadonnées des photographies</h2>
<p><strong>⚠️ Prérequis</strong></p>
<ul>
<li>Avoir terminé le chapitre 1 de la partie 2 et exécuté le script Python <code>fetch_themes.py</code> pour enrichir tous les graphes de photographies dans le dossier <code>photographies/</code> avec les labels de leurs thèmes Rameau.</li>
<li>le dossier <code>photographies_avec_themes/</code> doit exister et doit contenir les <strong>sérialisations Turtle des graphes de chaque photographie enrichies</strong> de leurs thèmes Rameau.</li>
</ul>
<h3 id="motivation">Motivation</h3>
<p>Notre but est de réussir à placer chaque photographie d’un lieu sur une carte, à l’endroit où se trouvait ce lieu.<br>
Pour cela il faut <strong>géocoder</strong> la photographie, c’est à dire lui lui associer des <strong>coordonnées géographiques</strong>, en l’occurrence celles du lieu pris en photo par Atget.</p>
<p>On a besoin pour cela de glaner <strong>l’information géographique</strong> qui se trouve dans les métadonnées d’une photographie, ce qui - on l’espère - fournira assez d’indices géographiques sur l’emplacement de cette photographie.</p>
<p>Dans le chapitre 1, on a vu que le <strong>titre</strong> de la photographie et ses <strong>thèmes Rameau</strong> contenaient des indices géographiques.</p>
<p>Parce que les grands modèles de langages sont conçus pour exploiter -entre autre- du texte, nous n’allons pas travailler directement avec les graphes de connaissance des photographies, mais avec une forme “sérialisée” en texte : leur rapport d’enrichissement produit par la fonction <code>build_summary_report()</code> dans le script <code>fetch_themes.py</code>.</p>
<p>Voici par exemple le rapport sur l’enrichissement de la photographie du <a href="https://gallica.bnf.fr/ark:/12148/btv1b10506998t#">Cabaret du Soleil d’or</a>  :</p>
<pre class=" language-raw"><code class="prism  language-raw">=== PHOTO : Au Soleil d'or : 84 [quatre-vingt-quatre] Rue S.t Sauveur (Modifié), [photographie] ===
Lien : http://data.bnf.fr/ark:/12148/cb40268281c#about
Thèmes assignés:
• « Dans l'art » - altLabels : « Représentation dans l'art », « Dans la sculpture », « Dans la peinture », « Représentation iconographique », « Dans les arts graphiques »
• « Cafés » - altLabels : « Cafés-bars », « Débits de boissons », « Estaminets », « Brasseries (cafés) », « Zincs (cafés) », « Bistrots », « Cafés publics », « Cafés (établissements) », « Bars »
• « Paris (France) »
• « Paris (France) -- Rue Saint-Sauveur » - altLabels : « Rue Saint-Sauveur (Paris, France) », « Saint-Sauveur, Rue (Paris, France) »
• « Enseignes » - altLabels : « Signes et indications », « Enseignes commerciales »
• « Ferronnerie d'art » - altLabels : « Serrurerie d'art », « Fer forgé, Objets en », « Fer ornemental », « Ferronnerie architecturale », « Ferrures », « Ferronneries », « Ferronnerie décorative », « Fer forgé », « Objets en fer forgé », « Ferronnerie (architecture) »
• « Soleil » - altLabels : « Physique solaire »
</code></pre>
<p>Une simple lecture de ce rapport permet de repérer un certain nombre d’indices géographiques, qu’on peut intuitivement organiser par granularité pour former une <strong>hiérarchie spatiale</strong> qui décrit à plusieurs échelles l’emplacement du lieu dans Paris :</p>
<pre class=" language-raw"><code class="prism  language-raw">📍 France [pays]
	└── 🏙️ Paris [ville]
		└── 🛣️ rue Saint-Sauveur [rue]
			└── 🏠 n° 84 rue Saint-Sauveur [adresse]
				└── ☀️ « Au Soleil d'or » [enseigne / toponyme]
</code></pre>
<p>Cette opération en apparence simple enchaîne plusieurs taches qui mobilisent des capacités cognitives humaines typiquement difficiles à transférer sous la forme de programme informatique :</p>
<ul>
<li><strong>identifier</strong> l’information géographique dans le titre et les thèmes nécessite de comprendre la langue française, de connaitre la géographie parisienne, …</li>
<li><strong>extraire</strong> cette information géographique nécessite de réussir à la séparer de son contexte et au besoin à la réinterpréter, par exemple pour que “84 [quatre-vingt-quatre] Rue S.t Sauveur”  soit compris comme l’adresse du n°84 rue Saint-Sauveur".</li>
<li><strong>organiser</strong> cette information de manière hiérarchique implique également une connaissance implicite importante: comment fonctionne une adresse, comment les humains structurent hiérarchiquement les lieux, etc.</li>
</ul>
<p>Réaliser cet enchaînement de tâches avec un ordinateur est un cas typique de <strong>traitement automatique du langage naturel</strong>.<br>
On pourrait imaginer la programmer naïvement sous la forme d’une chaîne de traitement, en utilisant par exemple des techniques à base de règles, mais cela serait à la fois très fastidieux et très fragile aux variations dans les formes de description des métadonnées.</p>
<p>Aujourd’hui, utiliser un <strong>grand modèle de langage (LLMs) génératifs</strong> pour réaliser cet enchaînement de taches en <strong>une seule étape</strong> est généralement l’approche la plus efficace.</p>
<p>Nous allons donc utiliser un LLM pour <strong>extraire et organiser hiérarchiquement l’information géographique</strong> contenue dans le titre et les thèmes Rameau des photographes.</p>
<p>Cette expérimentation sera réalisée avec les grands modèles de langages de <strong><a href="https://mistral.ai/fr">Mistral AI</a></strong>.</p>
<h3 id="premier-essai-naïf">Premier essai naïf</h3>
<p>En tant qu’utilisateur, le fonctionnement d’un modèle de langage est simple : c’est modèle statistique qui prend en entrée une information - par exemple un texte -, et génère un nouveau texte qui est conditionné par le contenu informationnel de l’entrée.</p>
<p>Ces modèles sont extrêmement performants pour réaliser de nombreuses taches de traitement automatique du langage naturel, car leur capacité d’attention et les connaissance stockées dans leur mémoire (apprise) les rendent capables de traitements complexes nécessitant des connaissances implicites importantes.</p>
<p>Ces capacités d’analyse sont maintenant bien connues et les LLM sont explicitement entraînés pour être utilisés comme outils de traitement que l’on peut guider à l’aide d’<strong>instructions</strong> (le <em>prompt</em>).</p>
<p>Testons les capacités du LLM de Mistral pour extraire la hiérarchie géographique du lieu décrit dans les métadonnées d’une photographie.<br>
Commençons avec le mode d’accès le plus grand public au LLM principal de Mistral :  le chatbot <em>Le Chat</em>.</p>
<p>Essayons de faire extraire au LLM la hiérarchie géographique parsemée dans le rapport sur la photographie du <a href="https://gallica.bnf.fr/ark:/12148/btv1b10506998t#">abaret du Soleil d’or</a> donné dans la section <strong>Motivation</strong>.</p>
<p>Pour guider un LLM, il faut un <em>prompt</em> décrivant la tache qu’il doit réaliser.<br>
S’il n’existe pas de “bible” de la rédaction de prompt, tous les LLMs sont entraînés pour comprendre des <em>prompts</em> dont structure générale est la suivante :</p>
<blockquote>
<p>a. Assigner un rôle au modèle pour la tache.<br>
b. Décrire la tâche à réaliser<br>
c. Si nécessaire, donner des règles spécifiques pour gérer les cas complexes, ambigus, etc.</p>
</blockquote>
<p>Voici un premier <em>prompt</em> très simple qu’on peut utiliser pour extraire la hiérarchie géographique à partir d’un rapport d’enrichissement de photographie :</p>
<pre class=" language-raw"><code class="prism  language-raw"># Rôle
Tu es un expert en extraction d'information géographique dans des métadonnées patrimoniales.

# Tâche
À partir d'un résumé descriptif d'une photographie ancienne, tu dois :
1. identifier les entités géographiques qui renseignent sur **la localisation du sujet de la photographie** dans l'espace ;
2. lister ces entités les uns après les autres.

# Règles
- les entités doivent être triée de la plus précise à la plus générale.

Le résumé à traiter sera donné dans le prochain input.
</code></pre>
<blockquote>
<p>ℹ️ Notez qu’on ne donne ici <strong>aucun exemple</strong> de traitement. Cette stratégie fondée uniquement sur des règles s’appelle <strong>0-shot prompting</strong>.</p>
</blockquote>
<blockquote>
<p>🎬 Rendez vous sur <a href="https://chat.mistral.ai/chat">https://chat.mistral.ai/chat</a> et donnez ce <em>prompt</em> au <em>chatbot</em>. Donnez ensuite le rapport d’enrichissement sur le cabaret du Soleil d’Or.</p>
</blockquote>
<p>Vous devriez constater que même avec un <em>prompt</em> grossier, le modèle fournit une réponse déjà très satisfaisante contenant une partie de la hiérarchie souhaitée.<br>
Par exemple :</p>
<pre class=" language-raw"><code class="prism  language-raw">Pour cette photographie, les entités géographiques permettant de localiser
 le sujet sont les suivantes :
1.  84 Rue Saint-Sauveur**
2.  Rue Saint-Sauveur (Paris, France)**
3.  Paris (France)
Si vous avez besoin d'une autre analyse, n'hésitez pas à me le demander !
</code></pre>
<blockquote>
<p>ℹ️ Du fait de la nature stochastique d’un LLM, sa réponse peut varier.</p>
</blockquote>
<p>Toutefois, le <em>prompt</em> contraint très peu la réponse du LLM : pas de format imposé, pas de liste de niveau hiérarchiques à extraire.<br>
Laissé libre, le modèle a “décidé” d’organiser la hiérarchie en liste numérotée, d’ajouter des commentaires, ignorer le toponyme ou ajouter des compléments entre parenthèses.</p>
<p>Cela ne pose pas de problèmes de compréhension à un humain, mais n’oublions pas que le notre but est d’extraire une hiérarchie exploitable dans un processus <strong>automatique</strong> de géocodage.<br>
Il faut donc que la sortie du LLM ne soit pas du simple texte, mais un texte formaté, standardisé, compréhensible par un programme.<br>
C’est ce qu’on appelle de  <strong>l’extraction structurée</strong> d’information.</p>
<h3 id="extraction-structurée-avec-le-chat">Extraction structurée avec <em>Le Chat</em></h3>
<p>Pour produire une réponse dans un format précis, interprétable informatiquement et qui contienne tous les niveaux hiérarchiques souhaités, nous devons guider bien plus strictement le modèle.</p>
<p>Une manière simple et particulièrement efficace consiste à ajouter au <em>prompt</em> au moins un exemple de rapport et la sortie attendue.<br>
Cette stratégie de guidage contextuel par l’exemple se nomme <em>few-shot prompting</em>.</p>
<blockquote>
<p>ℹ️ On trouve aussi parfois le terme de <em>few-shot training</em>, mais cette appellation porte à confusion et tend à disparaître. Si les réseaux de neurones profonds sont bien entraînés avec des exemples, cela n’a rien a voir avec le <em>prompting</em>. Les exemples dans le <em>prompt</em> font seulement partie du contexte accessible au modèle durant la génération du nouveau texte - cela guide son attention courante et son comportement, mais il n’apprend rien et ne stocke aucune nouvelle connaissance dans sa mémoire.</p>
</blockquote>
<p>A priori, tout format structuré est envisageable pour la hiérarchie inférée.<br>
Cependant, les LLMs sont généralement plus performants pour produire du JSON, parce qu’ils ont été entraînés pour les taches d’extraction structurée spécifiquement avec ce format.</p>
<p>Voici une représentation JSON possible de la hiérarchie donnée en <strong>motivation</strong> :</p>
<pre class=" language-json"><code class="prism  language-json"><span class="token punctuation">{</span>
	<span class="token string">"toponyme"</span><span class="token punctuation">:</span> <span class="token string">"Au Soleil d'Or"</span><span class="token punctuation">,</span>
	<span class="token string">"adresse"</span><span class="token punctuation">:</span> <span class="token string">"84 rue Saint-Sauveur"</span><span class="token punctuation">,</span>
	<span class="token string">"voie"</span> <span class="token punctuation">:</span> <span class="token string">"rue Saint-Sauveur"</span><span class="token punctuation">,</span>
	<span class="token string">"ville"</span><span class="token punctuation">:</span> <span class="token string">"Paris"</span><span class="token punctuation">,</span>
	<span class="token string">"pays"</span><span class="token punctuation">:</span> <span class="token string">"France"</span>
<span class="token punctuation">}</span>
</code></pre>
<blockquote>
<p>🎬 Modifiez le <em>prompt</em> d’extraction pour :</p>
<ol>
<li>Insérer une nouvelle règle : “- la réponse doit contenir <strong>uniquement</strong> du JSON suivant le schéma donné en exemple.”</li>
<li>Ajouter une quatrième section nommée  <code># Exemple</code> formatée ainsi</li>
</ol>
</blockquote>
<pre class=" language-raw"><code class="prism  language-raw"># Exemple
**Résumé descriptif **
&lt;Ajoutez le rapport de la section **motivation** sur le cabaret du Soleil d'Or&gt;

**Réponse JSON**
&lt;Ajoutez ici la représentation JSON donnée ci-dessus&gt;
</code></pre>
<blockquote>
<p>Créez un <strong>Nouveau Chat</strong> pour ne pas biaiser Mistral avec vos précédents messages, puis donnez le nouveau <em>prompt</em>.</p>
</blockquote>
<p>Pour tester les performances de ce nouveau <em>prompt</em> nous devons utiliser un nouveau rapport d’enrichissement puisque celui du cabaret du Soleil d’Or est déjà donné comme exemple.</p>
<blockquote>
<p>🎬 Testez avec le rapport du “Bon Puits” :</p>
</blockquote>
<pre class=" language-raw"><code class="prism  language-raw">=== PHOTO : Au Bon Puits : Rue Michel Le Comte 36 (Disparu en 1904), [photographie] ===
Lien : http://data.bnf.fr/ark:/12148/cb40268303v#about
Thèmes assignés:
• « Vin -- Industrie et commerce » - altLabels : « Commerce vinicole », « Industrie viticole », « Commerce viticole », « Production viticole », « Production vinicole », « Industrie vinicole »
• « Paris (France) -- Rue Michel-le-Comte » - altLabels : « Rue Michel-le-Comte (Paris, France) », « Michel-le-Comte, Rue (Paris, France) »
• « Paris (France) »
• « Enseignes » - altLabels : « Signes et indications », « Enseignes commerciales »
• « Ferronnerie d'art » - altLabels : « Ferronnerie architecturale », « Ferrures », « Serrurerie d'art », « Ferronneries », « Fer forgé, Objets en », « Fer ornemental », « Ferronnerie décorative », « Ferronnerie (architecture) », « Fer forgé », « Objets en fer forgé »
</code></pre>
<blockquote>
<p>Le modèle doit répondre la hiérarchie JSON suivante :</p>
</blockquote>
<pre class=" language-json"><code class="prism  language-json"><span class="token punctuation">{</span>
	<span class="token string">"toponyme"</span><span class="token punctuation">:</span> <span class="token string">"Au Bon Puits"</span><span class="token punctuation">,</span>
	<span class="token string">"adresse"</span><span class="token punctuation">:</span> <span class="token string">"36 rue Michel-Le-Comte"</span><span class="token punctuation">,</span>
	<span class="token string">"voie"</span><span class="token punctuation">:</span> <span class="token string">"rue Michel-Le-Comte"</span><span class="token punctuation">,</span>
	<span class="token string">"ville"</span><span class="token punctuation">:</span> <span class="token string">"Paris"</span><span class="token punctuation">,</span>
	<span class="token string">"pays"</span><span class="token punctuation">:</span> <span class="token string">"France"</span>
<span class="token punctuation">}</span>
</code></pre>
<blockquote>
<p>C’est mieux, non ? 🙂 On obtient le format attendu, avec tous les niveaux hiérarchiques souhaités, triés dans le bon ordre.</p>
</blockquote>
<p>Voyons maintenant comment automatiser ce traitement en Python grâce à la bibliothèque <code>mistralai</code> publiée par Mistral.</p>
<h3 id="extraction-structurée-par-llm-en-python-avec-mistralai">Extraction structurée par LLM en Python avec <code>mistralai</code></h3>
<p>Commençons par installer la bibliothèque avec <code>uv</code>.</p>
<blockquote>
<p>🎬 Dans un terminal, placez vous dans le dossier de travail <code>tnah-2026-partie2</code> et exécutez</p>
</blockquote>
<pre class=" language-bash"><code class="prism  language-bash">uv add mistralai
</code></pre>
<p>Créons ensuite un fichier de script Python qui contiendra le processus complet d’extraction structurée.</p>
<blockquote>
<p>🎬 Dans le même dossier, créez un nouveau fichier Python nommé <code>structured_extraction.py</code>. Par exemple depuis le terminal :</p>
</blockquote>
<pre class=" language-bash"><code class="prism  language-bash"><span class="token function">touch</span> structured_extraction.py
</code></pre>
<p>La <a href="https://docs.mistral.ai">documentation générale de Mistral</a> présente et illustre par l’exemple comment utiliser la bibliothèque <code>mistralai</code> pour faire de l’extraction structurée.</p>
<blockquote>
<p>🎬 Rendez-vous dans la documentation de Mistral, sur <a href="https://docs.mistral.ai">https://docs.mistral.ai</a>, et cherchez dans le menu gauche l’entrée <em>Structured Outputs</em> puis <em>JSON Mode</em>.<br>
Lisez la ligne de présentation. Comprenez-vous quelle est la spécificité de ce <em>JSON Mode</em> ?</p>
</blockquote>
<p>La page de documentation donne un exemple complet d’interaction avec le modèle LLM <code>mistral-large-latest</code>  hébergé sur leurs serveurs.</p>
<blockquote>
<p>📚 <code>mistral</code> est la famille de modèle, <code>mistral-large</code> est le plus modèle ayant le plus de paramètres, généralement le plus puissant. Le suffixe  <code>-latest</code> désigne la version la plus récente disponible.</p>
</blockquote>
<blockquote>
<p>🎬 Copiez cet exemple dans le fichier <code>structured_extraction.py</code> et :</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># 1. Commentez **momentanément la ligne suivante </span>
<span class="token comment">#api_key = os.environ["MISTRAL_API_KEY"]</span>
<span class="token comment"># Remplacez la par :</span>
api_key <span class="token operator">=</span> VOTRE_CLÉ_MISTRAL_ICI 

<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># le reste de l'exemple est inchangé</span>

<span class="token comment"># 2. Ajoutez à la fin du script la ligne suivante pour afficher le résultat </span>
<span class="token comment"># de la requête envoyée à Mistral :</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>chat_response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>🎬 Exécutez le script et vérifiez que le résultat est le même que sur la page de documentation.</p>
</blockquote>
<pre class=" language-bash"><code class="prism  language-bash">uv run structured_extraction.py
</code></pre>
<p>Nous voilà avec un script minimaliste mais fonctionnel pour utiliser le LLM <code>mistral-large</code> de manière programmatique.</p>
<blockquote>
<p>ℹ️ Notez que c’est la présence du paramètre <code>response_format = {"type": "json_object"}</code> dans l’appel à <code>client.chat.complete()</code> qui <strong>contraint</strong> le modèle à produire un résultat JSON. Sans lui le modèle se comporterait exactement comme le chatbot “Le Chat”, c’est à dire sans aucune garantie stricte de produire un JSON correct.</p>
</blockquote>
<h3 id="extraction-dune-hiérarchie-géographique-avec-mistral">Extraction d’une hiérarchie géographique avec Mistral</h3>
<p>Adaptons maintenant le script pour notre tache d’extraction de hiérarchie géographique !👏</p>
<p>Dans l’exemple, après avoir créé un client <code>Mistral</code> représentant la connexion au LLM distant, on définit la variable <code>messages</code> qui est une liste de messages à envoyer au modèle.<br>
Chaque message est représenté par un dictionnaire contenant deux clés : <code>"content"</code> et <code>"role"</code> .<br>
La clé <em>content</em> est triviale : c’est le contenu du message qui est donné au modèle.<br>
La clé <em>role</em> peut prendre plusieurs valeurs; deux nous intéressent ici :</p>
<ul>
<li><code>"role": "user"</code> : le LLM va considérer que le message est celui d’un utilisateur, et y porter une attention passagère. C’est typiquement le rôle adéquat pour envoyer le <strong>rapport d’enrichissement</strong> à traiter.</li>
<li><code>"role": "system"</code> : permet de définir un <strong>system prompt</strong>, c’est à dire une instruction générale que le modèle va conserver à “l’esprit” toute la durée de l’échange. Ce rôle est spécialement adapté pour donner les <strong>instructions de traitement</strong> au modèle.</li>
</ul>
<blockquote>
<p>🎬 Modifiez les messages stockés dans la variable <code>messages</code> pour :</p>
<ol>
<li>Donner dans un premier message avec le rôle <strong>system</strong> le prompt <em>few-shot</em> créé dans la section <strong>Extraction structurée avec <em>Le Chat</em></strong></li>
<li>Donner dans un second message avec le rôle <strong>user</strong> le rapport du “Bon Puits”.</li>
</ol>
<p>Exécutez à nouveau le script et vérifiez qu’il affiche bien la hiérarchie JSON dans le terminal !</p>
</blockquote>
<h3 id="automatisation-de-lextraction-structurée">Automatisation de l’extraction structurée</h3>
<p>Jusqu’ici, nous avons assigné manuellement le rapport d’enrichissement à traiter.<br>
Allons un cran plus loin en utilisant les fonctions définies dans <code>fetch_themes.py</code>, vues dans le chapitre 1, pour créer dynamiquement un rapport et l’envoyer à Mistral.</p>
<p>Nous avions utilisé <code>fetch_themes.py</code> comme un script exécutable, mais nous pouvons également l’utiliser comme un <strong>module python</strong> dont on peut importer les fonctions.</p>
<blockquote>
<p>🎬 Importez dans <code>structured_extraction.py</code> les fonctions <code>import_turtle_file()</code> <code>build_summary_report()</code> du fichier <code>fetch_themes.py</code> :</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">from</span> fetch_themes <span class="token keyword">import</span> build_summary_report<span class="token punctuation">,</span> fetch_themes
</code></pre>
<p>Nous pouvons ensuite utiliser ces fonctions pour lire un graphe de photographie et créer son rapport d’enrichissement.</p>
<blockquote>
<p>🎬 Après la création du client Mistral, utilisez les deux fonctions importées pour lire un fichier de graphe enrichi de votre choix depuis le dossier <code>photographies_avec_themes/</code> et créer son rapport d’enrichissement et :</p>
<ol>
<li>Stockez ce rapport dans un variable nommée <code>report</code></li>
<li>Affichez la avec <code>print()</code>.</li>
<li>Remplacez dans la déclaration des messages le contenu du message de rôle <em>user</em> par la variable <code>report</code></li>
<li>Exécutez le script pour vérifier qu’il traite bien le fichier de graphe que vous avez choisi !</li>
</ol>
</blockquote>
<h3 id="traitement-en-masse-des-graphes-de-photographie">Traitement en masse des graphes de photographie</h3>
<p>Reste une ultime étape : <strong>traiter tous les graphes</strong> et <strong>enregistrer le résultat JSON sur le disque</strong> pour la phase suivante de géocodage.</p>
<p>Il manque pour cela deux éléments :</p>
<ol>
<li>une boucle pour traiter chaque fichier de graphe du dossier  <code>photographies_avec_themes/</code> ;</li>
<li>une fonction d’enregistrement de la réponse du modèle en JSON.</li>
</ol>
<p>Commençons par le premier élément, où nous pouvons reprendre exactement la même logique que dans le script <code>fetch_themes.py</code>. N’hésitez pas à “piocher” dans ce script pour vous aider.</p>
<blockquote>
<p>🎬 Ajoutez l’import de la classe <code>Path</code> de <code>pathlib</code>:</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path
</code></pre>
<blockquote>
<p>🎬 Créez ensuite une variable <code>DIR</code> qui contient le chemin vers le dossier <code>photographies_avec_themes/</code>, puis récupérez la liste de tous les fichiers Turtle dans ce dossier.<br>
Notez que le dossier cible pour enregistrement les fichiers JSONs sera le même, pas besoin donc de distinguer <code>INPUT_DIR</code> et <code>OUTPUT_DIR</code>.</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python">DIR <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>parent  <span class="token operator">/</span>  <span class="token string">"photographies_avec_themes"</span>
turtle_files  <span class="token operator">=</span>  <span class="token builtin">list</span><span class="token punctuation">(</span>input_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">"*.ttl"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>🎬 Placez les appels à <code>import_turtle_file()</code> et <code>build_summary_report()</code>, la déclaration des messages, l’appel au modèle Mistral et l’instruction <code>print()</code> finale à l’intérieur d’une boucle qui itère sur chaque fichier de graphe :</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">for</span> turtle_file <span class="token keyword">in</span> turtle_files<span class="token punctuation">:</span>	
	<span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Traitement de {turtle_file}..."</span><span class="token punctuation">)</span>
	data  <span class="token operator">=</span>  import_turtle_file<span class="token punctuation">(</span>turtle_file<span class="token punctuation">)</span>
	report  <span class="token operator">=</span>  build_summary_report<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># La suite</span>
</code></pre>
<blockquote>
<p>⚠️ Attention à l’indentation !</p>
</blockquote>
<blockquote>
<p>🎬  Testez en exécutant le traitement pour <strong>1 seul graphe</strong> en utilisant le mécanisme de <em>slicing</em></p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">for</span> turtle_file <span class="token keyword">in</span> turtle_files<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># La suite</span>
</code></pre>
<blockquote>
<p>💡 Pour un code plus lisible, vous pouvez déplacer le prompt système dans une constante <code>SYSTEM_PROMPT</code> placée en début de script.</p>
</blockquote>
<blockquote>
<p>🎬 En début de script, ajoutez la déclaration de la fonction suivante, qui prend en paramètre le chemin vers le graphe <code>.ttl</code> stocké dans la variable de boucle <code>turtle_file</code> ainsi que la réponse du modèle Mistral <code>chat_response</code> et sauvegarde le résultat en JSON sur le disque dur à coté du fichier ` :</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">def</span>  <span class="token function">save_to_json</span><span class="token punctuation">(</span>chat_response<span class="token punctuation">,</span>  turtle_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token triple-quoted-string string">"""Sauvegarde la réponse de Milstra en JSON à coté du fichier `turtle_file`."""</span>
	<span class="token keyword">import</span>  json <span class="token comment"># &lt;-- Import à déplacer en entête du script pour suivre les bonnes 	output_file  =  turtle_file.with_suffix(".json")</span>
	data  <span class="token operator">=</span>  chat_response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content
	<span class="token keyword">with</span>  <span class="token builtin">open</span><span class="token punctuation">(</span>output_file<span class="token punctuation">,</span>  <span class="token string">"w"</span><span class="token punctuation">,</span>  encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>  <span class="token keyword">as</span>  f<span class="token punctuation">:</span>
		json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>data<span class="token punctuation">,</span>  f<span class="token punctuation">,</span>  ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>🎬  Appelez cette fonction juste après l’instruction <code>print(chat_response.choices[0].message.content)</code> en lui passant la réponse du modèle et le chemin vers le fichier Turtle du graphe.</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">for</span> turtle_file <span class="token keyword">in</span> turtle_files<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># contenu de la boucle</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span>chat_response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
	save_to_json<span class="token punctuation">(</span>chat_response<span class="token punctuation">,</span>  turtle_file<span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>🎬 Exécutez de nouveau le script puis <strong>vérifiez</strong> que le dossier <code>photographies_avec_themes/</code> contient bien un fichier JSON contenant la hiérarchie extraite pour le graphe choisi !</p>
</blockquote>
<p>Dans sa version gratuite, Mistral <strong>impose</strong> une limite de <strong>une requête maximum par seconde</strong>.<br>
Nous *<strong>devons</strong> donc forcer ce délai pour éviter que les requêtes soient rejetées par Mistral.<br>
Une manière simpliste mains fonctionnelle consiste à obliger le script à attendre un certain temps après chaque boucle, grâce à la fonction <code>sleep(n_seconds)</code> de la bibliothèque  <code>time</code>.</p>
<blockquote>
<p>🎬 Ajoutez l’import de <code>time</code> en entête du script :</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> time
</code></pre>
<blockquote>
<p>🎬 Forcez le script à attendre par exemple 1.5 seconde après avoir enregistré la hiérarchie du graphe courant en JSON, avant de passer au fichier suivant :</p>
</blockquote>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">for</span> turtle_file <span class="token keyword">in</span> turtle_files<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token comment"># contenu de la boucle</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span>chat_response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
	save_to_json<span class="token punctuation">(</span>chat_response<span class="token punctuation">,</span>  turtle_file<span class="token punctuation">)</span>
	time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>🎬 Vous pouvez maintenant retirer le <em>slicing</em> sans crainte puis exécuter enfin l’extraction structurée pour toutes les photographies ! 🥳</p>
</blockquote>
<h3 id="🏁-fin-du-chapitre-2">🏁 Fin du chapitre 2</h3>
<p>Félicitations, vous voici équipé avec un script fonctionnel <strong>d’extraction structurée</strong> utilisant un LLM de Mistral ! 🎉</p>
<p>Une fois le traitement effectué sur tous les graphes, chaque fichier <code>.ttl</code> devrait avoir son fichier compagnon <code>.json</code> décrivant la hiérarchie géographique de la photographie.</p>
<p>Vous avez maintenant toutes les données utiles pour <strong>géocoder</strong> et <strong>cartographier</strong> le font Atget - ce qu’on verra dans la <strong>partie 3</strong> !</p>
</div>
</body>

</html>
